{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA FROM ESHKOL AUGUST 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eshkol said:\n",
    "\n",
    "The matrices named fncd are 4D: 128x128x100x33, where horizontal resolution is 50 m and vertical is 40 m. \n",
    "\n",
    "The 33 are the size distribution bins according to the same rd.mat vector that I gave you in all previous files.\n",
    "\n",
    "Number concentration = sum( fncd ) on the forth dimension \n",
    "\n",
    "effective radius - re(i,j,k) = sum( rd^3*fncd(i,j,k) )/ sum( rd^2*fncd(i,j,k) )\n",
    "\n",
    "So from the nc files (each contains x,y,z,time,rn,rd,p,rho,FNCD) I need to extract:\n",
    "\n",
    "- 'FNCD': <class 'netCDF4._netCDF4.Variable'>\n",
    "\n",
    "- 'rd': <class 'netCDF4._netCDF4.Variable'>\n",
    "\n",
    "Each nc file has:\n",
    "\n",
    "[variable units shape]\n",
    "\n",
    "- x m (128,)\n",
    "\n",
    "- y m (128,)\n",
    "\n",
    "- z m (100,)\n",
    "\n",
    "- time d (1,)\n",
    "\n",
    "- rn micron (33,)\n",
    "\n",
    "- rd micron (33,)\n",
    "\n",
    "- p mb (100,)\n",
    "\n",
    "- r ho g/m3 (100,)\n",
    "\n",
    "- FNCD #/cm3/bin  (1, 33, 100, 128, 128)\n",
    "\n",
    "-----\n",
    "\n",
    "To work with nc files you need netcdf4 package. \n",
    "\n",
    "So in the terminal do:\n",
    "\n",
    "`conda install -c anaconda netcdf4`\n",
    "\n",
    "then use: `from netCDF4 import Dataset`\n",
    "\n",
    "-----\n",
    "\n",
    "What is FNCD?\n",
    "\n",
    "I tried to read:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Raindrop_size_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.patches as mpatches\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import math \n",
    "import scipy.io as sio\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_distribution(r,N,re,ve):\n",
    "    C = ((re*ve)**(2-(1/ve)))/math.gamma((1/ve)-2)\n",
    "    t = N*C*(r**((1/ve)-3))\n",
    "    n = t*np.exp(-r/(re*ve))\n",
    "    return n\n",
    "\n",
    "def gamma_distribution_tofit(r,N,alpha,b):\n",
    "    # defination from: https://web.archive.org/web/20171213043637/http://nit.colorado.edu/shdom/shdomdoc/\n",
    "    a = (b**(alpha+1))*(N/(math.gamma(alpha+1)))#N = a Gamma(alpha+1)/ b^(alpha+1)\n",
    "    n = a*(r**alpha)*np.exp(-r*b)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters should be known in advence.\n",
    "dx,dy,dz=(1e-3*50,1e-3*50,1e-3*40) # in km\n",
    "nz = 100\n",
    "z_min = 0\n",
    "z_max = 1e-3*40*nz\n",
    "zgrid = np.linspace(z_min, z_max-dz ,nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections in /wdata/clouds_from_weizmann/BOMEX_512X512X170_500CCN_20m of format BOMEX_512x512x170_500CCN_20m_micro_256_*.com3D_int_2.nc is 301\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/wdata/clouds_from_weizmann/BOMEX_512X512X170_500CCN_20m' # data should be stored under this path \n",
    "# format_ = 'BOMEX_128x128x100_2000CCN_50m_micro_128_*.com3D_int_2.nc'# lod one was .com3D_int_2.nc\n",
    "format_ = 'BOMEX_512x512x170_500CCN_20m_micro_256_*.com3D_int_2.nc' # the format of the files to search for.\n",
    "volumes_paths = sorted(glob.glob(data_dir + '/'+format_))\n",
    "volume_stamps = [re.findall('_(\\d*).com3D_int_2.nc', i)[0] for i in volumes_paths]\n",
    "volume_stamps = [int(i) for i in volume_stamps]# convert to integer \n",
    "print(f'Number of sections in {data_dir} of format {format_} is {len(volumes_paths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOWVOL = True # if true, show evrey volume\n",
    "IF_SAVE_txt = True\n",
    "PRINT_MICRO_PHYSICS = False\n",
    "FIT_GAMMA = False # if it True, then fit gamma parameters with non-linear least squares fit\n",
    "# BUT, the fit works strange, it doesn't fit good parameters to all vaxels. Some get huge values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example File loading and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  /wdata/clouds_from_weizmann/BOMEX_512X512X170_500CCN_20m/BOMEX_512x512x170_500CCN_20m_micro_256_0000021600.com3D_int_2.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_64BIT_OFFSET data model, file format NETCDF3):\n",
       "    dimensions(sizes): x(512), y(512), z(170), time(1), rn(33), rd(33), ib(33)\n",
       "    variables(dimensions): float32 \u001b[4mx\u001b[0m(x), float32 \u001b[4my\u001b[0m(y), float32 \u001b[4mz\u001b[0m(z), float32 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mrn\u001b[0m(rn), float32 \u001b[4mrd\u001b[0m(rd), float32 \u001b[4mp\u001b[0m(z), float32 \u001b[4mrho\u001b[0m(z), float32 \u001b[4mFNCD\u001b[0m(time,rd,z,y,x)\n",
       "    groups: "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = volumes_paths[0]\n",
    "print('loading ',file)\n",
    "nc = Dataset(file)\n",
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED\n",
    "def get_dx_dy(nc):\n",
    "    \"\"\"\n",
    "        Extracts dx, dy from .nc file\n",
    "    \"\"\"\n",
    "    x, y = nc.variables['x'][:].data, nc.variables['y'][:].data\n",
    "    dx, dy = np.unique(np.diff(x)), np.unique(np.diff(y)) \n",
    "    if len(dx) != 1:\n",
    "            raise(f'dx is not uniform. dx: {np.diff(x)}')\n",
    "    if len(dy) != 1:\n",
    "            raise(f'dy is not uniform. dy: {np.diff(y)}')\n",
    "    \n",
    "    return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  /wdata/clouds_from_weizmann/BOMEX_512X512X170_500CCN_20m/BOMEX_512x512x170_500CCN_20m_micro_256_0000021600.com3D_int_2.nc\n",
      "performing operations(?)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubi/miniconda3/envs/pyshdom/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/shubi/miniconda3/envs/pyshdom/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving /wdata/clouds_from_weizmann/BOMEX_512X512X170_500CCN_20m/BOMEX_512x512x170_500CCN_20m_micro_256_0000021600.txt\n",
      "RE MIN = 2.2485601902008057\n",
      "RE MAX = 17.531906127929688\n",
      "VE MIN = 0.00581858167424798\n",
      "VE MAX = 0.5857473015785217\n",
      "saving reff, veff , lwc .mat file to: /wdata/clouds_from_weizmann/BOMEX_512X512X170_500CCN_20m/BOMEX_512x512x170_500CCN_20m_micro_256_0000021600_ONLY_RE_VE_LWC.mat\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in volumes_paths:\n",
    "    print('loading ',file)\n",
    "    nc = Dataset(file)\n",
    "    \n",
    "    rd = nc.variables['rd'][:].data # units micron\n",
    "    FNCD = np.squeeze(nc.variables['FNCD'][:].data) # units #/cm3/bin\n",
    "    # note that the shape of FNCD is now (33, 100, 128, 128)\n",
    "    \n",
    "    # LWC:\n",
    "    # what Eshkol explained with old data: rho - density kg/m^3  - you can use this to convert mixing ratio (LWC [g/kg]]) to liquid water density [g/m^-3]]\n",
    "    # rho - density g/m3:\n",
    "    rho = 1e6\n",
    "    # Eshkol said: The rho in the output is of the whole voxel (so its mostly density of dry air and water vapor. \n",
    "    # I don't think you need it. For liquid water content you can take water density as constant of  1 g/cm^3.\n",
    "    # rho = nc.variables['rho'][:].data\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    print('performing operations(?)...')\n",
    "    DOPC = FNCD# distribution of droplets consintration, it is given as histogram\n",
    "    e_DOPC = DOPC\n",
    "    e_rd = rd[:,np.newaxis, np.newaxis, np.newaxis]\n",
    "    # ---------------------------------------------\n",
    "    Dx = np.diff(rd)[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    DOPC = DOPC[:-1,...]/Dx # it is the PDF\n",
    "    rd = rd[:-1, np.newaxis, np.newaxis, np.newaxis]\n",
    "\n",
    "    #---------------------------------------------\n",
    "    # calculate reff, veff, LWC from the FNCD (here it doesn't assume gamma distribution):\n",
    "    reff3D = np.trapz(DOPC*rd**3,rd, axis=0)/np.trapz(DOPC*rd**2,rd, axis=0)\n",
    "    veff3D = np.trapz(((rd-reff3D)**2)*(rd**2)*DOPC,rd, axis=0)/(reff3D**2*np.trapz(DOPC*rd**2,rd, axis=0))\n",
    "    LWC3D = (1e-12)*(4/3)*np.pi*rho*np.trapz((rd**3)*DOPC,rd, axis=0)\n",
    "    # above it uses integral of the PDF, below it is as Eshkol suggested, just to use sum:\n",
    "    # I think the integral is better choice espesialy using np.trapz, but I will use the sum as Yoav told to doas Eshkol instructed.\n",
    "    e_reff3D = np.sum( e_rd**3*e_DOPC , axis=0)/ np.sum( e_rd**2*e_DOPC , axis=0)\n",
    "    e_veff3D = np.sum( ((e_rd-e_reff3D)**2)*(e_rd**2)*e_DOPC , axis=0)/ np.sum( e_reff3D**2*e_DOPC*e_rd**2 , axis=0)\n",
    "    e_LWC3D = (1e-12)*(4/3)*np.pi*rho*np.sum((e_rd**3)*e_DOPC, axis=0)\n",
    "    # units of rho are g/m^3, of DOPC are #/cm3/um, of r um. The units of the result LWC are [g/m^3]\n",
    "    NC3D = np.sum(DOPC*Dx, axis=0)# total consintration\n",
    "\n",
    "    # avoide nans:\n",
    "    for arr in [e_LWC3D, e_reff3D, e_veff3D, LWC3D, reff3D, veff3D]:\n",
    "        arr = np.nan_to_num(arr)\n",
    "\n",
    "    # here the 3d shape is (100, 128, 128)\n",
    "    RE = np.transpose(e_reff3D, (2, 1, 0))\n",
    "    VE = np.transpose(e_veff3D, (2, 1, 0))\n",
    "    LWC = np.transpose(e_LWC3D, (2, 1, 0))\n",
    "    NCT = np.transpose(NC3D, (2, 1, 0))\n",
    "    # here the 3d shape is (128, 128,100)\n",
    "    \n",
    "    # this is a good place to filter voxels.\n",
    "    # Eshkol said voxels with LWC < 0.01 can be considered as not cloudy ones.\n",
    "    lwc_treshold = 0.01 # [g/m^3]\n",
    "    # In addition, I want to filter voxels with NC<1.\n",
    "    NC_treshold = 1\n",
    "    for arr in [RE, VE, NCT, LWC]:\n",
    "        arr[LWC<lwc_treshold]  = 0\n",
    "\n",
    "    for arr in [RE, VE, LWC, NCT]:\n",
    "        arr[NCT<NC_treshold]  = 0        \n",
    "    \n",
    "    # re treshold:\n",
    "#     re_treshold = 35\n",
    "#     VE[RE>re_treshold]  = 0\n",
    "#     LWC[RE>re_treshold] = 0\n",
    "#     NCT[RE>re_treshold] = 0\n",
    "#     RE[RE>re_treshold]  = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # fit gamma:\n",
    "    if(FIT_GAMMA):\n",
    "        \n",
    "        indxs = np.argwhere(LWC > 0)# cloudy voxel indexes\n",
    "        for vox_indx in tqdm(indxs):\n",
    "            DOPC_voxel = DOPC[:,vox_indx[2],vox_indx[1],vox_indx[0]] # distribution of droplets consintration \n",
    "            # the order vox_indx[2],vox_indx[1],vox_indx[0] is because x = np.transpose(x, (2, 1, 0))          \n",
    "            try:\n",
    "                PRINT_MICRO_PHYSICS = False\n",
    "                rd_ = np.squeeze(rd)\n",
    "                popt, pcov = curve_fit(gamma_distribution_tofit, rd_, DOPC_voxel)\n",
    "                fited_gamma = gamma_distribution_tofit(rd_, *popt)\n",
    "                fit_reff = np.trapz(fited_gamma*rd_**3,rd_, axis=0)/np.trapz(fited_gamma*rd_**2,rd_, axis=0)\n",
    "                fit_veff = np.trapz(((rd_-fit_reff)**2)*(rd_**2)*fited_gamma,rd_, axis=0)/(fit_reff**2*np.trapz(fited_gamma*rd_**2,rd_, axis=0))\n",
    "                fit_LWC = (1e-12)*(4/3)*np.pi*rho*np.trapz((rd_**3)*fited_gamma,rd_, axis=0)\n",
    "                if(np.isnan(fit_reff) or np.isnan(fit_veff) or np.isnan(fit_LWC)):\n",
    "                    continue\n",
    "                \n",
    "                if(fit_reff>re_treshold or fit_LWC<lwc_treshold or popt[0] < NC_treshold):\n",
    "                    continue\n",
    "                    \n",
    "                if(PRINT_MICRO_PHYSICS):\n",
    "                    print(\"fited LWC = {} [g/m^3]\".format(fit_LWC))\n",
    "                    print(\"fited reff = {} [um]\".format(fit_reff))\n",
    "                    print(\"fited veff = {}\\n\".format(fit_veff))\n",
    "                    \n",
    "                RE[vox_indx[0],vox_indx[1],vox_indx[2]]  = fit_reff\n",
    "                VE[vox_indx[0],vox_indx[1],vox_indx[2]]  = fit_veff\n",
    "                LWC[vox_indx[0],vox_indx[1],vox_indx[2]] = fit_LWC \n",
    "            except:\n",
    "                print(\"Optimal parameters not found.\\It will uses original parameters:\")\n",
    "                print(\"calculated LWC = {} [g/m^3]\".format(LWC[vox_indx[0],vox_indx[1],vox_indx[2]]))\n",
    "                print(\"calculated reff = {} [um]\".format(RE[vox_indx[0],vox_indx[1],vox_indx[2]]))\n",
    "                print(\"calculated veff = {}\".format(VE[vox_indx[0],vox_indx[1],vox_indx[2]]))\n",
    "    \n",
    "    \n",
    "    # do the padding here. Pad with zeros on the sides\n",
    "    npad = ((1,1),(1,1),(0,0))\n",
    "    for arr in [LWC, NCT, RE, VE]:\n",
    "        arr = np.pad(arr, pad_width=npad, mode='constant', constant_values=0.0)\n",
    "    \n",
    "    if(IF_SAVE_txt):\n",
    "        comment_line = \"Data from Eshkol Itan\"\n",
    "        original_name = os.path.basename(file)\n",
    "        file_name = original_name.split('.')[0]+'.txt'\n",
    "        file_name = os.path.join(data_dir,file_name)\n",
    "        print('saving {}'.format(file_name))\n",
    "        \n",
    "        # print RE min max and VE nim max:\n",
    "        m=RE[RE>0]\n",
    "        print(f\"RE MIN = {m.min()}\")\n",
    "        print(f\"RE MAX = {RE.max()}\")\n",
    "\n",
    "        m=VE[VE>0]\n",
    "        print(f\"VE MIN = {m.min()}\")\n",
    "        print(f\"VE MAX = {VE.max()}\")\n",
    "        # --------finish to print RE min max and VE nim max:\n",
    "\n",
    "        np.savetxt(file_name, X=np.array([RE.shape]), fmt='%d', header=comment_line)\n",
    "\n",
    "        with open(file_name, 'ab') as f:\n",
    "            np.savetxt(f, X=np.concatenate((np.array([dx, dy]), zgrid)).reshape(1,-1), fmt='%2.3f')\n",
    "            nx, ny, nz = RE.shape\n",
    "            totext_lwc = LWC\n",
    "            totext_reff = RE\n",
    "            totext_veff = VE\n",
    "            y, x, z = np.meshgrid(range(ny), range(nx), range(nz))\n",
    "            data = np.vstack((x.ravel(), y.ravel(), z.ravel(), totext_lwc.ravel(), totext_reff.ravel(), totext_veff.ravel())).T\n",
    "            np.savetxt(f, X=data, fmt='%d %d %d %.5f %.3f %.5f')        \n",
    "        \n",
    "        # save only RE,VE(+LWC) for visualization in matlab:\n",
    "        file_name = original_name.split('.')[0]+'_ONLY_RE_VE_LWC.mat'\n",
    "        file_name = os.path.join(data_dir,file_name)\n",
    "        \n",
    "        x, y, z = nc.variables['x'][:].data, nc.variables['y'][:].data, nc.variables['z'][:].data\n",
    "\n",
    "        sio.savemat(file_name, dict(reff=RE,veff=VE,lwc=LWC, x=x,y=y,z=z))  \n",
    "        print(f\"saving reff, veff , lwc .mat file to: {file_name}\\n\\n\")\n",
    "        \n",
    "    break\n",
    "            \n",
    "# in pyshdom liquid water content lwc is of units (g/m^3)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyshdom] *",
   "language": "python",
   "name": "conda-env-pyshdom-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
